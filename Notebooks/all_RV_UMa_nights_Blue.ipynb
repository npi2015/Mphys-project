{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import DAOStarFinder\n",
    "import ccdproc as ccdp\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from photutils.aperture import CircularAperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_data_and_headers(*args):\n",
    "    all_data = list()\n",
    "    all_headers = list()\n",
    "    for path in args:\n",
    "        files = ccdp.ImageFileCollection(path)\n",
    "        night_data = [i for i in files.data()]\n",
    "        night_headers = [i for i in files.headers()]\n",
    "        all_data.extend(night_data)\n",
    "        all_headers.extend(night_headers)\n",
    "    return all_data, all_headers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "filter = 'Blue'\n",
    "\n",
    "night_1 = '../reduced-lights_2022_03_20/' + filter\n",
    "night_2 = '../reduced-lights_2022_03_22/' + filter\n",
    "night_3 = '../reduced-lights_2022_03_24/' + filter\n",
    "\n",
    "data, headers = get_data_and_headers(night_1, night_2, night_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_sources(array):\n",
    "    mean, median, std = sigma_clipped_stats(array, sigma=2.5)\n",
    "    daofind = DAOStarFinder(fwhm=9.0, threshold=5.*std)\n",
    "    sources = daofind(array - median)\n",
    "    return sources\n",
    "\n",
    "def image_trimmer(sources, array):\n",
    "    local_df = sources.to_pandas()\n",
    "    image_size = array.shape\n",
    "    x_trim = image_size[1] * 0.05\n",
    "    y_trim = image_size[0] * 0.05\n",
    "    local_df = local_df[(local_df['xcentroid'] - x_trim > 0) & (local_df['xcentroid'] + x_trim < image_size[1])]\n",
    "    local_df = local_df[(local_df['ycentroid'] - y_trim > 0) & (local_df['ycentroid'] + y_trim < image_size[0])]\n",
    "    return local_df.reset_index(drop = True).drop('id', axis = 'columns')\n",
    "\n",
    "def excluding_duplicates(df, fwhm):\n",
    "    #Taking initial comparison values from first row\n",
    "    xcenter, ycenter, flux = df.iloc[0][['xcentroid', 'ycentroid', 'flux']]\n",
    "    last_index = 0\n",
    "    #Including first row in result\n",
    "    filters = [True]\n",
    "\n",
    "    #Skipping first row in comparisons\n",
    "    for index, row in df.iloc[1:].iterrows():\n",
    "        if (xcenter - 3*fwhm <= row['xcentroid'] <= 3*fwhm + xcenter) or (ycenter - 3*fwhm <= row[\n",
    "            'ycentroid'] <= 3*fwhm + ycenter):\n",
    "            # Once we have the two that are very close to each other we want to keep the one with the highest flux\n",
    "            if df.iloc[last_index]['flux'] > row['flux']:\n",
    "                filters.append(False)\n",
    "            else:\n",
    "                filters[last_index] = False\n",
    "                filters.append(True)\n",
    "                xcenter = row['xcentroid']\n",
    "                ycenter = row['ycentroid']\n",
    "                last_index = index\n",
    "        else:\n",
    "            filters.append(True)\n",
    "            # Updating values to compare based on latest accepted row\n",
    "            xcenter = row['xcentroid']\n",
    "            ycenter = row['ycentroid']\n",
    "            last_index = index\n",
    "    result = df.loc[filters]\n",
    "    return result.reset_index(drop=True)\n",
    "\n",
    "def find_nearest(sources_1, sources_2):\n",
    "    positions = np.transpose((sources_1['xcentroid'], sources_1['ycentroid']))\n",
    "    positions_2 = np.transpose((sources_2['xcentroid'], sources_2['ycentroid']))\n",
    "    mapping_dict = dict()\n",
    "    for index, value in enumerate(positions):\n",
    "        difference = np.subtract(positions_2, value)\n",
    "        squared_difference = np.square(difference)\n",
    "        min_index = np.sqrt(squared_difference.sum(axis = 1)).argmin()\n",
    "        if index in mapping_dict:\n",
    "            old_difference_in_flux = abs(sources_1['flux'][index] - sources_2['flux'][mapping_dict[index]])\n",
    "            new_difference_in_flux = abs(sources_1['flux'][index] - sources_2['flux'][min_index])\n",
    "            if old_difference_in_flux > new_difference_in_flux:\n",
    "                mapping_dict[index] = min_index\n",
    "        else:\n",
    "            mapping_dict[index] = min_index\n",
    "    for key, item in mapping_dict.items():\n",
    "        x_1, y_1 = sources_1.iloc[key]['xcentroid'], sources_1.iloc[key]['ycentroid']\n",
    "        x_2, y_2 = sources_2.iloc[item]['xcentroid'], sources_2.iloc[item]['ycentroid']\n",
    "        distance = np.sqrt((x_1-x_2)**2+(y_1-y_2)**2)\n",
    "        if distance > 100:\n",
    "            mapping_dict[key] = np.nan\n",
    "    return mapping_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from photutils.aperture import CircularAperture, CircularAnnulus, ApertureStats, aperture_photometry\n",
    "from astropy.stats import SigmaClip\n",
    "import itertools\n",
    "\n",
    "def signal_to_noise_ratio_v3(image_array, positions_df, r_start, r_end, step_size, delta_r, return_df = False):\n",
    "    sigclip = SigmaClip(sigma=3, maxiters=5)\n",
    "    # List of the aperture radius\n",
    "    aperture_radius = list()\n",
    "\n",
    "    # List of lists with the signal-to-noise ratios at each aperture\n",
    "    all_snr_list = list()\n",
    "\n",
    "    # Empty dataframe for putting everything in later\n",
    "    snr_df = pd.DataFrame()\n",
    "\n",
    "    # Get the positions that have a nan in them and ignore them\n",
    "    nan_indexes = np.argwhere(pd.isnull(positions_df))\n",
    "    if nan_indexes.size > 0: # Only works with a np.array\n",
    "        no_nan_positions = list(positions_df[~pd.isnull(positions_df)])\n",
    "    else: # Only works with a list\n",
    "        no_nan_positions = list(positions_df)\n",
    "\n",
    "    for r in np.arange(r_start, r_end + step_size, step_size):\n",
    "\n",
    "        annulus_aperture = CircularAnnulus(no_nan_positions, r_in = r, r_out = r + delta_r)\n",
    "        bkg_stats = ApertureStats(image_array, annulus_aperture, sigma_clip=sigclip)\n",
    "        bkg_median = bkg_stats.median\n",
    "        apertures = CircularAperture(no_nan_positions, r)\n",
    "        phot_table = aperture_photometry(image_array, apertures)\n",
    "        aper_stats = ApertureStats(image_array, apertures, sigma_clip=None)\n",
    "        aperture_area = aper_stats.sum_aper_area.value\n",
    "        total_bkg = bkg_median * aperture_area\n",
    "        phot_bkgsub = phot_table['aperture_sum'] - total_bkg\n",
    "        signal_to_noise_ratio = list(phot_bkgsub / total_bkg)\n",
    "        aperture_radius.append(r)\n",
    "        for nan_index in nan_indexes:\n",
    "            signal_to_noise_ratio.insert(nan_index[0], np.nan)\n",
    "        all_snr_list.append(signal_to_noise_ratio)\n",
    "\n",
    "    # Transpose the snr list\n",
    "    stars_snr = list(map(list, itertools.zip_longest(*all_snr_list, fillvalue=None)))\n",
    "\n",
    "    # Add the aperture radii in the first column\n",
    "    snr_df['Aperture radii'] = aperture_radius\n",
    "\n",
    "    # Create a column with the snr of each star at different radii\n",
    "    for star_index, snr_list in enumerate(stars_snr):\n",
    "        snr_df[f'Star {star_index}'] = snr_list\n",
    "\n",
    "    indexes_of_max_snr = list(snr_df.idxmax())[1:] # Exclude the first one since it's the aperture radii\n",
    "\n",
    "    optimal_radii = [snr_df['Aperture radii'].iloc[int(i)] if not np.isnan(i) else np.nan for i in indexes_of_max_snr]\n",
    "    optimal_radius = np.nanmean(optimal_radii)\n",
    "\n",
    "    if return_df:\n",
    "        return snr_df\n",
    "    else:\n",
    "        return optimal_radius"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def aperture_calculation(image_array, positions_df, r, delta_r, exp_time, gain, return_table = False):\n",
    "    sigclip = SigmaClip(sigma=3, maxiters=5)\n",
    "    magnitudes_list = list()\n",
    "    fluxes_list = list()\n",
    "    std_magnitudes_list = list()\n",
    "    for position in positions_df:\n",
    "        if position is not np.nan:\n",
    "            annulus_aperture = CircularAnnulus(position, r_in = r, r_out = r + delta_r)\n",
    "            bkg_stats = ApertureStats(image_array, annulus_aperture, sigma_clip=sigclip)\n",
    "            bkg_median = bkg_stats.median\n",
    "            apertures = CircularAperture(position, r)\n",
    "            phot_table = aperture_photometry(image_array, apertures)\n",
    "            aper_stats = ApertureStats(image_array, apertures, sigma_clip=None)\n",
    "            aperture_area = aper_stats.sum_aper_area.value\n",
    "            total_bkg = bkg_median * aperture_area\n",
    "            phot_bkgsub = aper_stats.sum - total_bkg\n",
    "            phot_table['aperture_sum_bkgsub'] = phot_bkgsub\n",
    "            flux = (gain * phot_bkgsub) / exp_time\n",
    "            mag = 25 - 2.5 * np.log10(flux)\n",
    "            std_mag = 1.0857 / np.sqrt(aper_stats.sum)\n",
    "            magnitudes_list.append(mag)\n",
    "            fluxes_list.append(flux)\n",
    "            std_magnitudes_list.append(std_mag)\n",
    "        else:\n",
    "            magnitudes_list.append(np.nan)\n",
    "            fluxes_list.append(np.nan)\n",
    "            std_magnitudes_list.append(np.nan)\n",
    "    if return_table:\n",
    "        return phot_table\n",
    "    else:\n",
    "        return magnitudes_list, fluxes_list, std_magnitudes_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dictionary_list = list()\n",
    "sources_first_array = find_sources(data[0])\n",
    "trimmed_sources_first_array = image_trimmer(sources_first_array, data[0])\n",
    "sources_first_array_no_duplicates = excluding_duplicates(trimmed_sources_first_array, 9)\n",
    "\n",
    "for index in range(1, len(data)):\n",
    "    sources_next_array = find_sources(data[index])\n",
    "    trimmed_sources_next_array = image_trimmer(sources_next_array, data[index])\n",
    "    sources_next_array_no_duplicates = excluding_duplicates(trimmed_sources_next_array, 9)\n",
    "    mapping_dictionary = find_nearest(sources_first_array_no_duplicates, sources_next_array_no_duplicates)\n",
    "    dictionary_list.append(mapping_dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "method_2_dict = dict()\n",
    "method_2_dict[0] = list(dictionary_list[0].keys())\n",
    "for index, dictionary in enumerate(dictionary_list):\n",
    "    method_2_dict[index+1] = list(dictionary.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_2_list_sources = list()\n",
    "\n",
    "for key, item in method_2_dict.items():\n",
    "    temp_list = list()\n",
    "    found_sources = find_sources(data[key])\n",
    "    trimmed_image = image_trimmer(found_sources, data[key])\n",
    "    final_df = excluding_duplicates(trimmed_image, 9)\n",
    "    for i in item:\n",
    "        if i is np.nan:\n",
    "            temp_list.append(np.nan)\n",
    "        else:\n",
    "            # temp_list.append(final_df.iloc[i]['flux'])\n",
    "            temp_list.append((final_df.iloc[i]['xcentroid'], final_df.iloc[i]['ycentroid']))\n",
    "    method_2_list_sources.append(temp_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_positions_dict = dict()\n",
    "for lst in method_2_list_sources:\n",
    "    for index, item in enumerate(lst):\n",
    "        if index not in all_positions_dict.keys():\n",
    "            all_positions_dict[index] = list()\n",
    "            all_positions_dict[index].append(item)\n",
    "        else:\n",
    "            all_positions_dict[index].append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "position_df = pd.DataFrame(all_positions_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_positions = list()\n",
    "y_positions = list()\n",
    "\n",
    "for i in position_df.iloc[:, 5]:\n",
    "    if type(i) is tuple:\n",
    "        x_positions.append(i[0])\n",
    "        y_positions.append(i[1])\n",
    "    else:\n",
    "        x_positions.append(np.nan)\n",
    "        y_positions.append(np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dx = [i - x_positions[0] for i in x_positions]\n",
    "dy = [i - y_positions[0] for i in y_positions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(dx, 'x')\n",
    "plt.plot(dy, 'o')\n",
    "plt.savefig('./Images/DxDy.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_magnitudes = list()\n",
    "all_fluxes = list()\n",
    "all_mags_errors = list()\n",
    "for index in range(len(position_df)):\n",
    "    print(index)\n",
    "    positions = np.array(position_df.loc[index])\n",
    "    loop_array = data[index]\n",
    "    optimal_aperture_list = signal_to_noise_ratio_v3(loop_array, positions, 1, 30, 0.1, 10)\n",
    "    magnitudes, fluxes, magnitude_errors = aperture_calculation(loop_array, positions, optimal_aperture_list, 10, 16, 1)\n",
    "    all_fluxes.append(fluxes)\n",
    "    all_magnitudes.append(magnitudes)\n",
    "    all_mags_errors.append(magnitude_errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_magnitudes_transposed = list(map(list, itertools.zip_longest(*all_magnitudes, fillvalue=None)))\n",
    "all_fluxes_transposed = list(map(list, itertools.zip_longest(*all_fluxes, fillvalue=None)))\n",
    "all_magnitude_error_transposed = list(map(list, itertools.zip_longest(*all_mags_errors, fillvalue = None)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sources_first_array_no_duplicates.iloc[34]['xcentroid'], sources_first_array_no_duplicates.iloc[34]['ycentroid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RV_UMa_index = 23\n",
    "\n",
    "RV_UMa_magnitudes = [all_magnitudes_transposed[RV_UMa_index]]\n",
    "RV_UMa_fluxes = [all_fluxes_transposed[RV_UMa_index]]\n",
    "RV_Uma_mag_error = [all_magnitude_error_transposed[RV_UMa_index]]\n",
    "\n",
    "\n",
    "saturated_stars_and_RV_UMa = [3, 13, 28,RV_UMa_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stars_index =[i for i in range(len(sources_first_array_no_duplicates)) if i not in saturated_stars_and_RV_UMa]\n",
    "magnitude_list_standard_stars = [all_magnitudes_transposed[i] for i in stars_index]\n",
    "flux_list_standard_stars = [all_fluxes_transposed[i] for i in stars_index]\n",
    "mag_error_standard_stars = [all_magnitude_error_transposed[i] for i in stars_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, lst in enumerate(magnitude_list_standard_stars):\n",
    "    plt.plot(lst, 'x')\n",
    "    plt.title(f'Star {stars_index[index]}')\n",
    "    plt.xlabel('Array number')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_stars_index = [0, 1, 2, 4, 8, 10, 11, 15, 16, 18, 21, 22, 24, 27, 31, 33,34, 36]\n",
    "\n",
    "corrected_stars_index = [i for i in range(len(sources_first_array_no_duplicates)) if i not in bad_stars_index and i not in saturated_stars_and_RV_UMa]\n",
    "\n",
    "flux_list_standard_stars = [all_fluxes_transposed[i] for i in corrected_stars_index]\n",
    "magnitude_list_standard_stars = [all_magnitudes_transposed[i] for i in corrected_stars_index]\n",
    "error_list_standard_stars = [all_magnitude_error_transposed[i] for i in corrected_stars_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we transpose the all_magnitudes list so that each list contains all the magnitudes of each star\n",
    "all_flux_offsets_standard_stars = list()\n",
    "all_magnitude_offsets_standard_stars = list()\n",
    "all_magnitude_offset_errors_standard_stars = list()\n",
    "\n",
    "for index, flux_list in enumerate(all_fluxes_transposed):\n",
    "    if index in corrected_stars_index:\n",
    "        offset = [flux_list[0]- i for i in flux_list]\n",
    "        all_flux_offsets_standard_stars.append(offset)\n",
    "\n",
    "for index, mag_list, error_list in zip(range(len(all_magnitudes_transposed)), all_magnitudes_transposed, all_magnitude_error_transposed):\n",
    "    if index in corrected_stars_index:\n",
    "        offset = [mag_list[0]- i for i in mag_list]\n",
    "        offset_error = [error_list[0] + i for i in error_list]\n",
    "        all_magnitude_offsets_standard_stars.append(offset)\n",
    "        all_magnitude_offset_errors_standard_stars.append(offset_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_magnitude_offsets = np.nanmean(all_magnitude_offsets_standard_stars, axis = 0)\n",
    "\n",
    "std_magnitude_offsets = np.nanstd(all_magnitude_offsets_standard_stars, axis = 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corrected_RV_UMa_magnitude = np.array(RV_UMa_magnitudes[0]) + mean_magnitude_offsets\n",
    "RV_UMa_error = np.array(RV_Uma_mag_error) + std_magnitude_offsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrected_magnitudes = list()\n",
    "corrected_magnitude_error = list()\n",
    "for star in magnitude_list_standard_stars:\n",
    "    corrected_magnitudes.append(np.array(star) + mean_magnitude_offsets)\n",
    "\n",
    "for star_error in error_list_standard_stars:\n",
    "    corrected_magnitude_error.append(np.array(star_error) + std_magnitude_offsets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Corrected magnitudes')\n",
    "print(np.nanmean(corrected_magnitudes, axis = 1))\n",
    "print(max(np.nanstd(corrected_magnitudes, axis = 1)))\n",
    "print('\\n\\n')\n",
    "print('Corrected RV UMa')\n",
    "print(np.nanmean(RV_UMa_magnitudes[0]))\n",
    "print(np.nanstd(RV_UMa_magnitudes[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for star in magnitude_list_standard_stars:\n",
    "    plt.plot(star, 'x')\n",
    "\n",
    "plt.plot(RV_UMa_magnitudes[0], 'o')\n",
    "plt.gca().invert_yaxis();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Not corrected magnitudes')\n",
    "print(np.mean(np.nanstd(magnitude_list_standard_stars, axis = 1)))\n",
    "print(max(np.nanstd(magnitude_list_standard_stars, axis = 1)))\n",
    "print('Not corrected RV UMa')\n",
    "print(np.nanmean(corrected_RV_UMa_magnitude))\n",
    "print(np.nanstd(corrected_RV_UMa_magnitude))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting with time on the x-axis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "from astropy.time import Time\n",
    "\n",
    "times = [datetime.datetime.strptime(header[\"DATE-OBS\"], '%Y-%m-%dT%H:%M:%S.%f') for header in headers]\n",
    "times = [Time(i).jd for i in times]\n",
    "t = [time - times[0] for time in times]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(times, corrected_RV_UMa_magnitude, 'x')\n",
    "plt.xlabel('time (days)')\n",
    "plt.ylabel('Magnitude');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "period = 0.46806 # period in days\n",
    "phase = np.array(t)/period - np.floor(np.array(t)/period)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "star_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, star, star_error in zip(range(len(corrected_magnitudes)), corrected_magnitudes, corrected_magnitude_error):\n",
    "    plt.errorbar(phase, star,  yerr = star_error, capsize = 5, marker = 'x', markersize = 2, label = f'Star {corrected_stars_index[index]}')\n",
    "plt.errorbar(phase, corrected_RV_UMa_magnitude, yerr = RV_UMa_error,marker = 'o', capsize = 5,  color = 'blue', markersize = 2)\n",
    "# plt.legend()\n",
    "plt.gca().invert_yaxis();\n",
    "plt.xlabel('phase')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.savefig('./Images/Corrected_blue_filter');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for star in magnitude_list_standard_stars:\n",
    "    plt.plot(phase, star, 'x')\n",
    "\n",
    "plt.plot(phase, RV_UMa_magnitudes[0], 'o', markersize = 2, color = 'blue')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.savefig('./Images/Uncorrected_phase_image');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Move everything to txt file\n",
    "\n",
    "with open(f'RV_UMaData{filter.upper()}.txt', 'w') as f:\n",
    "    f.write(str(filter))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(phase))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(corrected_RV_UMa_magnitude))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(RV_UMa_error))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(np.array(times)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(f'StarData{filter.upper()}.txt', 'w') as f:\n",
    "    f.write(str(phase))\n",
    "    f.write('\\n\\n\\n')\n",
    "    f.write(str(corrected_magnitudes))\n",
    "    f.write('\\n\\n\\n')\n",
    "    f.write(str(corrected_magnitude_error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}