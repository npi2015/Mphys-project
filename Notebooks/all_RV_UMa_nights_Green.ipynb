{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import DAOStarFinder\n",
    "import ccdproc as ccdp\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from photutils.aperture import CircularAperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_data_and_headers(*args):\n",
    "    all_data = list()\n",
    "    all_headers = list()\n",
    "    for path in args:\n",
    "        files = ccdp.ImageFileCollection(path)\n",
    "        night_data = [i for i in files.data()]\n",
    "        night_headers = [i for i in files.headers()]\n",
    "        all_data.extend(night_data)\n",
    "        all_headers.extend(night_headers)\n",
    "    return all_data, all_headers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m night_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../reduced-lights_2022_03_22/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mfilter\u001B[39m\n\u001B[0;32m      4\u001B[0m night_3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../reduced-lights_2022_03_24/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mfilter\u001B[39m\n\u001B[1;32m----> 6\u001B[0m data, headers \u001B[38;5;241m=\u001B[39m \u001B[43mget_data_and_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnight_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnight_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnight_3\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mget_data_and_headers\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m args:\n\u001B[0;32m      5\u001B[0m     files \u001B[38;5;241m=\u001B[39m ccdp\u001B[38;5;241m.\u001B[39mImageFileCollection(path)\n\u001B[1;32m----> 6\u001B[0m     night_data \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m files\u001B[38;5;241m.\u001B[39mdata()]\n\u001B[0;32m      7\u001B[0m     night_headers \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m files\u001B[38;5;241m.\u001B[39mheaders()]\n\u001B[0;32m      8\u001B[0m     all_data\u001B[38;5;241m.\u001B[39mextend(night_data)\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m args:\n\u001B[0;32m      5\u001B[0m     files \u001B[38;5;241m=\u001B[39m ccdp\u001B[38;5;241m.\u001B[39mImageFileCollection(path)\n\u001B[1;32m----> 6\u001B[0m     night_data \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m files\u001B[38;5;241m.\u001B[39mdata()]\n\u001B[0;32m      7\u001B[0m     night_headers \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m files\u001B[38;5;241m.\u001B[39mheaders()]\n\u001B[0;32m      8\u001B[0m     all_data\u001B[38;5;241m.\u001B[39mextend(night_data)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ccdproc\\image_collection.py:907\u001B[0m, in \u001B[0;36mImageFileCollection._generator\u001B[1;34m(self, return_type, save_with_name, save_location, clobber, overwrite, do_not_scale_image_data, return_fname, ccd_kwargs, **kwd)\u001B[0m\n\u001B[0;32m    905\u001B[0m     return_thing \u001B[38;5;241m=\u001B[39m fits\u001B[38;5;241m.\u001B[39mgetheader(full_path, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mext)\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 907\u001B[0m     return_thing \u001B[38;5;241m=\u001B[39m fits\u001B[38;5;241m.\u001B[39mgetdata(full_path, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mext, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39madd_kwargs)\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mccd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    909\u001B[0m     return_thing \u001B[38;5;241m=\u001B[39m fits_ccddata_reader(\n\u001B[0;32m    910\u001B[0m         full_path, hdu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mext, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mccd_kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\io\\fits\\convenience.py:206\u001B[0m, in \u001B[0;36mgetdata\u001B[1;34m(filename, header, lower, upper, view, *args, **kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    205\u001B[0m     hdu \u001B[38;5;241m=\u001B[39m hdulist[extidx]\n\u001B[1;32m--> 206\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mhdu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m ext_given:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\utils\\decorators.py:777\u001B[0m, in \u001B[0;36mlazyproperty.__get__\u001B[1;34m(self, obj, owner)\u001B[0m\n\u001B[0;32m    775\u001B[0m         val \u001B[38;5;241m=\u001B[39m obj_dict\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key, _NotFound)\n\u001B[0;32m    776\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m _NotFound:\n\u001B[1;32m--> 777\u001B[0m             val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    778\u001B[0m             obj_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key] \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m val\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\image.py:235\u001B[0m, in \u001B[0;36m_ImageBaseHDU.data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_axes) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 235\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_scaled_image_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_header_scale_info(data\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\image.py:779\u001B[0m, in \u001B[0;36m_ImageBaseHDU._get_scaled_image_data\u001B[1;34m(self, offset, shape)\u001B[0m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;124;03mInternal function for reading image data from a file and apply scale\u001B[39;00m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;124;03mfactors to it.  Normally this is used for the entire image, but it\u001B[39;00m\n\u001B[0;32m    774\u001B[0m \u001B[38;5;124;03msupports alternate offset/shape for Section support.\u001B[39;00m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    777\u001B[0m code \u001B[38;5;241m=\u001B[39m BITPIX2DTYPE[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_orig_bitpix]\n\u001B[1;32m--> 779\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_raw_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m raw_data\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m=\u001B[39m raw_data\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mnewbyteorder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    782\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_not_scale_image_data \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_orig_bzero \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_orig_bscale \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blank \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# No further conversion of the data is necessary\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\base.py:522\u001B[0m, in \u001B[0;36m_BaseHDU._get_raw_data\u001B[1;34m(self, shape, code, offset)\u001B[0m\n\u001B[0;32m    519\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndarray(shape, dtype\u001B[38;5;241m=\u001B[39mcode, buffer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer,\n\u001B[0;32m    520\u001B[0m                       offset\u001B[38;5;241m=\u001B[39moffset)\n\u001B[0;32m    521\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file:\n\u001B[1;32m--> 522\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    524\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\astropy\\io\\fits\\file.py:300\u001B[0m, in \u001B[0;36m_File.readarray\u001B[1;34m(self, size, offset, dtype, shape)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;66;03m# This would also work:\u001B[39;00m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;66;03m# self._file.seek(0, 2)   # moves to the end\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 300\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mmap \u001B[38;5;241m=\u001B[39m \u001B[43mmmap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileno\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m                           \u001B[49m\u001B[43maccess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccess_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[43m                           \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;66;03m# NOTE: mode='readonly' results in the memory-mapping\u001B[39;00m\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;66;03m# using the ACCESS_COPY mode in mmap so that users can\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;66;03m# least allows the file to be opened even if the\u001B[39;00m\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;66;03m# resulting arrays will be truly read-only.\u001B[39;00m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOMEM \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreadonly\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación"
     ]
    }
   ],
   "source": [
    "filter = 'Red'\n",
    "night_1 = '../reduced-lights_2022_03_20/' + filter\n",
    "night_2 = '../reduced-lights_2022_03_22/' + filter\n",
    "night_3 = '../reduced-lights_2022_03_24/' + filter\n",
    "\n",
    "data, headers = get_data_and_headers(night_1, night_2, night_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_sources(array):\n",
    "    mean, median, std = sigma_clipped_stats(array, sigma=2.5)\n",
    "    daofind = DAOStarFinder(fwhm=9.0, threshold=5.*std)\n",
    "    sources = daofind(array - median)\n",
    "    return sources\n",
    "\n",
    "def image_trimmer(sources, array):\n",
    "    local_df = sources.to_pandas()\n",
    "    image_size = array.shape\n",
    "    x_trim = image_size[1] * 0.05\n",
    "    y_trim = image_size[0] * 0.05\n",
    "    local_df = local_df[(local_df['xcentroid'] - x_trim > 0) & (local_df['xcentroid'] + x_trim < image_size[1])]\n",
    "    local_df = local_df[(local_df['ycentroid'] - y_trim > 0) & (local_df['ycentroid'] + y_trim < image_size[0])]\n",
    "    return local_df.reset_index(drop = True).drop('id', axis = 'columns')\n",
    "\n",
    "def excluding_duplicates(df, fwhm):\n",
    "    #Taking initial comparison values from first row\n",
    "    xcenter, ycenter, flux = df.iloc[0][['xcentroid', 'ycentroid', 'flux']]\n",
    "    last_index = 0\n",
    "    #Including first row in result\n",
    "    filters = [True]\n",
    "\n",
    "    #Skipping first row in comparisons\n",
    "    for index, row in df.iloc[1:].iterrows():\n",
    "        if (xcenter - 3*fwhm <= row['xcentroid'] <= 3*fwhm + xcenter) or (ycenter - 3*fwhm <= row[\n",
    "            'ycentroid'] <= 3*fwhm + ycenter):\n",
    "            # Once we have the two that are very close to each other we want to keep the one with the highest flux\n",
    "            if df.iloc[last_index]['flux'] > row['flux']:\n",
    "                filters.append(False)\n",
    "            else:\n",
    "                filters[last_index] = False\n",
    "                filters.append(True)\n",
    "                xcenter = row['xcentroid']\n",
    "                ycenter = row['ycentroid']\n",
    "                last_index = index\n",
    "        else:\n",
    "            filters.append(True)\n",
    "            # Updating values to compare based on latest accepted row\n",
    "            xcenter = row['xcentroid']\n",
    "            ycenter = row['ycentroid']\n",
    "            last_index = index\n",
    "    result = df.loc[filters]\n",
    "    return result.reset_index(drop=True)\n",
    "\n",
    "def find_nearest(sources_1, sources_2):\n",
    "    positions = np.transpose((sources_1['xcentroid'], sources_1['ycentroid']))\n",
    "    positions_2 = np.transpose((sources_2['xcentroid'], sources_2['ycentroid']))\n",
    "    mapping_dict = dict()\n",
    "    for index, value in enumerate(positions):\n",
    "        difference = np.subtract(positions_2, value)\n",
    "        squared_difference = np.square(difference)\n",
    "        min_index = np.sqrt(squared_difference.sum(axis = 1)).argmin()\n",
    "        if index in mapping_dict:\n",
    "            old_difference_in_flux = abs(sources_1['flux'][index] - sources_2['flux'][mapping_dict[index]])\n",
    "            new_difference_in_flux = abs(sources_1['flux'][index] - sources_2['flux'][min_index])\n",
    "            if old_difference_in_flux > new_difference_in_flux:\n",
    "                mapping_dict[index] = min_index\n",
    "        else:\n",
    "            mapping_dict[index] = min_index\n",
    "    for key, item in mapping_dict.items():\n",
    "        x_1, y_1 = sources_1.iloc[key]['xcentroid'], sources_1.iloc[key]['ycentroid']\n",
    "        x_2, y_2 = sources_2.iloc[item]['xcentroid'], sources_2.iloc[item]['ycentroid']\n",
    "        distance = np.sqrt((x_1-x_2)**2+(y_1-y_2)**2)\n",
    "        if distance > 100:\n",
    "            mapping_dict[key] = np.nan\n",
    "    return mapping_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from photutils.aperture import CircularAperture, CircularAnnulus, ApertureStats, aperture_photometry\n",
    "from astropy.stats import SigmaClip\n",
    "import itertools\n",
    "\n",
    "def signal_to_noise_ratio_v3(image_array, positions_df, r_start, r_end, step_size, delta_r, return_df = False):\n",
    "    sigclip = SigmaClip(sigma=3, maxiters=5)\n",
    "    # List of the aperture radius\n",
    "    aperture_radius = list()\n",
    "\n",
    "    # List of lists with the signal-to-noise ratios at each aperture\n",
    "    all_snr_list = list()\n",
    "\n",
    "    # Empty dataframe for putting everything in later\n",
    "    snr_df = pd.DataFrame()\n",
    "\n",
    "    # Get the positions that have a nan in them and ignore them\n",
    "    nan_indexes = np.argwhere(pd.isnull(positions_df))\n",
    "    if nan_indexes.size > 0: # Only works with a np.array\n",
    "        no_nan_positions = list(positions_df[~pd.isnull(positions_df)])\n",
    "    else: # Only works with a list\n",
    "        no_nan_positions = list(positions_df)\n",
    "\n",
    "    for r in np.arange(r_start, r_end + step_size, step_size):\n",
    "\n",
    "        annulus_aperture = CircularAnnulus(no_nan_positions, r_in = r, r_out = r + delta_r)\n",
    "        bkg_stats = ApertureStats(image_array, annulus_aperture, sigma_clip=sigclip)\n",
    "        bkg_median = bkg_stats.median\n",
    "        apertures = CircularAperture(no_nan_positions, r)\n",
    "        phot_table = aperture_photometry(image_array, apertures)\n",
    "        aper_stats = ApertureStats(image_array, apertures, sigma_clip=None)\n",
    "        aperture_area = aper_stats.sum_aper_area.value\n",
    "        total_bkg = bkg_median * aperture_area\n",
    "        phot_bkgsub = phot_table['aperture_sum'] - total_bkg\n",
    "        signal_to_noise_ratio = list(phot_bkgsub / total_bkg)\n",
    "        aperture_radius.append(r)\n",
    "        for nan_index in nan_indexes:\n",
    "            signal_to_noise_ratio.insert(nan_index[0], np.nan)\n",
    "        all_snr_list.append(signal_to_noise_ratio)\n",
    "\n",
    "    # Transpose the snr list\n",
    "    stars_snr = list(map(list, itertools.zip_longest(*all_snr_list, fillvalue=None)))\n",
    "\n",
    "    # Add the aperture radii in the first column\n",
    "    snr_df['Aperture radii'] = aperture_radius\n",
    "\n",
    "    # Create a column with the snr of each star at different radii\n",
    "    for star_index, snr_list in enumerate(stars_snr):\n",
    "        snr_df[f'Star {star_index}'] = snr_list\n",
    "\n",
    "    indexes_of_max_snr = list(snr_df.idxmax())[1:] # Exclude the first one since it's the aperture radii\n",
    "\n",
    "    optimal_radii = [snr_df['Aperture radii'].iloc[int(i)] if not np.isnan(i) else np.nan for i in indexes_of_max_snr]\n",
    "    optimal_radius = np.nanmean(optimal_radii)\n",
    "\n",
    "    if return_df:\n",
    "        return snr_df\n",
    "    else:\n",
    "        return optimal_radius"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def aperture_calculation(image_array, positions_df, r, delta_r, exp_time, gain, return_table = False):\n",
    "    sigclip = SigmaClip(sigma=3, maxiters=5)\n",
    "    magnitudes_list = list()\n",
    "    fluxes_list = list()\n",
    "    for position in positions_df:\n",
    "        if position is not np.nan:\n",
    "            annulus_aperture = CircularAnnulus(position, r_in = r, r_out = r + delta_r)\n",
    "            bkg_stats = ApertureStats(image_array, annulus_aperture, sigma_clip=sigclip)\n",
    "            bkg_median = bkg_stats.median\n",
    "            apertures = CircularAperture(position, r)\n",
    "            phot_table = aperture_photometry(image_array, apertures)\n",
    "            aper_stats = ApertureStats(image_array, apertures, sigma_clip=None)\n",
    "            aperture_area = aper_stats.sum_aper_area.value\n",
    "            total_bkg = bkg_median * aperture_area\n",
    "            phot_bkgsub = phot_table['aperture_sum'] - total_bkg\n",
    "            phot_table['aperture_sum_bkgsub'] = phot_bkgsub\n",
    "            flux = (gain * phot_bkgsub) / exp_time\n",
    "            mag = 25 - 2.5 * np.log10(flux)\n",
    "            magnitudes_list.append(mag[0])\n",
    "            fluxes_list.append(flux[0])\n",
    "        else:\n",
    "            magnitudes_list.append(np.nan)\n",
    "            fluxes_list.append(np.nan)\n",
    "    if return_table:\n",
    "        return phot_table\n",
    "    else:\n",
    "        return magnitudes_list, fluxes_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionary_list = list()\n",
    "sources_first_array = find_sources(data[0])\n",
    "trimmed_sources_first_array = image_trimmer(sources_first_array, data[0])\n",
    "sources_first_array_no_duplicates = excluding_duplicates(trimmed_sources_first_array, 9)\n",
    "\n",
    "for index in range(1, len(data)):\n",
    "    sources_next_array = find_sources(data[index])\n",
    "    trimmed_sources_next_array = image_trimmer(sources_next_array, data[index])\n",
    "    sources_next_array_no_duplicates = excluding_duplicates(trimmed_sources_next_array, 9)\n",
    "    mapping_dictionary = find_nearest(sources_first_array_no_duplicates, sources_next_array_no_duplicates)\n",
    "    dictionary_list.append(mapping_dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_2_dict = dict()\n",
    "method_2_dict[0] = list(dictionary_list[0].keys())\n",
    "for index, dictionary in enumerate(dictionary_list):\n",
    "    method_2_dict[index+1] = list(dictionary.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_2_list_sources = list()\n",
    "\n",
    "for key, item in method_2_dict.items():\n",
    "    temp_list = list()\n",
    "    found_sources = find_sources(data[key])\n",
    "    trimmed_image = image_trimmer(found_sources, data[key])\n",
    "    final_df = excluding_duplicates(trimmed_image, 9)\n",
    "    for i in item:\n",
    "        if i is np.nan:\n",
    "            temp_list.append(np.nan)\n",
    "        else:\n",
    "            # temp_list.append(final_df.iloc[i]['flux'])\n",
    "            temp_list.append((final_df.iloc[i]['xcentroid'], final_df.iloc[i]['ycentroid']))\n",
    "    method_2_list_sources.append(temp_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_positions_dict = dict()\n",
    "for lst in method_2_list_sources:\n",
    "    for index, item in enumerate(lst):\n",
    "        if index not in all_positions_dict.keys():\n",
    "            all_positions_dict[index] = list()\n",
    "            all_positions_dict[index].append(item)\n",
    "        else:\n",
    "            all_positions_dict[index].append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "position_df = pd.DataFrame(all_positions_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_magnitudes = list()\n",
    "all_fluxes = list()\n",
    "for index in range(len(position_df)):\n",
    "    print(index)\n",
    "    positions = np.array(position_df.loc[index])\n",
    "    loop_array = data[index]\n",
    "    optimal_aperture_list = signal_to_noise_ratio_v3(loop_array, positions, 1, 30, 0.1, 10)\n",
    "    magnitudes, fluxes = aperture_calculation(loop_array, positions, optimal_aperture_list, 10, 16, 1)\n",
    "    all_fluxes.append(fluxes)\n",
    "    all_magnitudes.append(magnitudes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_magnitudes_transposed = list(map(list, itertools.zip_longest(*all_magnitudes, fillvalue=None)))\n",
    "all_fluxes_transposed = list(map(list, itertools.zip_longest(*all_fluxes, fillvalue=None)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sources_first_array_no_duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RV_UMa_index = 23\n",
    "\n",
    "RV_UMa_magnitudes = [all_magnitudes_transposed[RV_UMa_index]]\n",
    "RV_UMa_fluxes = [all_fluxes_transposed[RV_UMa_index]]\n",
    "\n",
    "\n",
    "saturated_stars_and_RV_UMa = [3, 13, 28,RV_UMa_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stars_index =[i for i in range(len(sources_first_array_no_duplicates)) if i not in saturated_stars_and_RV_UMa]\n",
    "magnitude_list_standard_stars = [all_magnitudes_transposed[i] for i in stars_index]\n",
    "flux_list_standard_stars = [all_fluxes_transposed[i] for i in stars_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, lst in enumerate(magnitude_list_standard_stars):\n",
    "    plt.plot(lst, 'x')\n",
    "    plt.title(f'Star {stars_index[index]}')\n",
    "    plt.xlabel('Array number')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_stars_index = [0, 1, 2, 8, 10, 11, 15, 16, 18, 21, 22, 24, 27, 31, 33, 36]\n",
    "\n",
    "corrected_stars_index = [i for i in range(len(sources_first_array_no_duplicates)) if i not in bad_stars_index and i not in saturated_stars_and_RV_UMa]\n",
    "\n",
    "flux_list_standard_stars = [all_fluxes_transposed[i] for i in corrected_stars_index]\n",
    "magnitude_list_standard_stars = [all_magnitudes_transposed[i] for i in corrected_stars_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we transpose the all_magnitudes list so that each list contains all the magnitudes of each star\n",
    "all_flux_offsets_standard_stars = list()\n",
    "all_magnitude_offsets_standard_stars = list()\n",
    "for index, flux_list in enumerate(all_fluxes_transposed):\n",
    "    if index in corrected_stars_index:\n",
    "        offset = [flux_list[0]- i for i in flux_list]\n",
    "        all_flux_offsets_standard_stars.append(offset)\n",
    "\n",
    "for index, flux_list in enumerate(all_magnitudes_transposed):\n",
    "    if index in corrected_stars_index:\n",
    "        offset = [flux_list[0]- i for i in flux_list]\n",
    "        all_magnitude_offsets_standard_stars.append(offset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_magnitude_offsets = np.nanmean(all_magnitude_offsets_standard_stars, axis = 0)\n",
    "mean_flux_offsets = np.nanmean(all_flux_offsets_standard_stars, axis = 0)\n",
    "\n",
    "std_magnitude_offsets = np.nanstd(all_magnitude_offsets_standard_stars, axis = 0)\n",
    "std_flux_offsets = np.nanstd(all_flux_offsets_standard_stars, axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corrected_RV_UMa_flux = np.array(RV_UMa_fluxes[0]) + mean_flux_offsets\n",
    "corrected_RV_UMa_magnitude = np.array(RV_UMa_magnitudes[0]) + mean_magnitude_offsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrected_magnitudes = list()\n",
    "for star in magnitude_list_standard_stars:\n",
    "    corrected_magnitudes.append(np.array(star) + mean_magnitude_offsets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, star in enumerate(corrected_magnitudes):\n",
    "    plt.plot(star, 'x', label = f'Star {corrected_stars_index[index]}')\n",
    "plt.plot(corrected_RV_UMa_magnitude, 'o', markersize = 2)\n",
    "# plt.legend()\n",
    "plt.gca().invert_yaxis();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Corrected magnitudes')\n",
    "print(np.mean(np.nanstd(corrected_magnitudes, axis = 1)))\n",
    "print(max(np.nanstd(corrected_magnitudes, axis = 1)))\n",
    "print('\\n\\n')\n",
    "print('Corrected RV UMa')\n",
    "print(np.nanmean(RV_UMa_magnitudes[0]))\n",
    "print(np.nanstd(RV_UMa_magnitudes[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for star in magnitude_list_standard_stars:\n",
    "    plt.plot(star, 'x')\n",
    "\n",
    "plt.plot(RV_UMa_magnitudes[0], 'o')\n",
    "plt.gca().invert_yaxis();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Not corrected magnitudes')\n",
    "print(np.mean(np.nanstd(magnitude_list_standard_stars, axis = 1)))\n",
    "print(max(np.nanstd(magnitude_list_standard_stars, axis = 1)))\n",
    "print('Not corrected RV UMa')\n",
    "print(np.mean(corrected_RV_UMa_magnitude))\n",
    "print(np.std(corrected_RV_UMa_magnitude))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting with time on the x-axis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "times = [datetime.datetime.strptime(header[\"DATE-OBS\"], '%Y-%m-%dT%H:%M:%S.%f') for header in headers]\n",
    "t = [(time - times[0]).total_seconds() for time in times]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(t, corrected_RV_UMa_magnitude, 'x')\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Magnitude');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "period = 0.47 # period in days\n",
    "period_seconds = period*24*3600\n",
    "phase = np.array(t)/period_seconds - np.floor(np.array(t)/period_seconds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, star in enumerate(corrected_magnitudes):\n",
    "    plt.plot(phase, star, 'x', label = f'Star {corrected_stars_index[index]}')\n",
    "plt.plot(phase, corrected_RV_UMa_magnitude, 'o', markersize = 2)\n",
    "# plt.legend()\n",
    "plt.gca().invert_yaxis();\n",
    "plt.xlabel('phase')\n",
    "plt.ylabel('Magnitude');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Move everything to txt file\n",
    "\n",
    "with open(f'RV_UMaData{filter.upper()}.txt', 'w') as f:\n",
    "    f.write(str(filter))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(phase))\n",
    "    f.write('\\n\\n\\n***************************************************************\\n\\n\\n')\n",
    "    f.write(str(star))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}